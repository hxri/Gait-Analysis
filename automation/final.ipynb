{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_center(img,is_round=True):\n",
    "    Y = img.mean(axis=1)\n",
    "    X = img.mean(axis=0)\n",
    "    Y_ = np.sum(np.arange(Y.shape[0]) * Y)/np.sum(Y)\n",
    "    X_ = np.sum(np.arange(X.shape[0]) * X)/np.sum(X)\n",
    "    if is_round:\n",
    "        return int(round(X_)),int(round(Y_))\n",
    "    return X_,Y_\n",
    "\n",
    "def image_extract(img,newsize):\n",
    "    if (len(np.where(img.mean(axis=0)!=0)[0]) != 0):\n",
    "        x_s = np.where(img.mean(axis=0)!=0)[0].min()\n",
    "        x_e = np.where(img.mean(axis=0)!=0)[0].max()\n",
    "        \n",
    "        y_s = np.where(img.mean(axis=1)!=0)[0].min()\n",
    "        y_e = np.where(img.mean(axis=1)!=0)[0].max()\n",
    "        \n",
    "        x_c,_ = mass_center(img)\n",
    "        x_s = x_c-newsize[1]//2\n",
    "        x_e = x_c+newsize[1]//2\n",
    "        img = img[y_s:y_e,x_s if x_s>0 else 0:x_e if x_e<img.shape[1] else img.shape[1]]\n",
    "        return cv2.resize(img,newsize)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = {'Abhirami': 0,\n",
    "            'Aswathy': 1,\n",
    "            'Ayana': 2,\n",
    "            'Lekshmi': 3,\n",
    "            'Nandana': 4,\n",
    "            'Parthiv': 5,\n",
    "            'Shilpa': 6,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 book, 728.4ms\n",
      "Speed: 2.0ms preprocess, 728.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 cell phone, 703.6ms\n",
      "Speed: 0.0ms preprocess, 703.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 690.6ms\n",
      "Speed: 1.0ms preprocess, 690.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 710.0ms\n",
      "Speed: 1.0ms preprocess, 710.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 730.4ms\n",
      "Speed: 1.0ms preprocess, 730.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 712.8ms\n",
      "Speed: 2.0ms preprocess, 712.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 751.2ms\n",
      "Speed: 2.0ms preprocess, 751.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 749.4ms\n",
      "Speed: 1.0ms preprocess, 749.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 778.4ms\n",
      "Speed: 3.0ms preprocess, 778.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 697.4ms\n",
      "Speed: 1.0ms preprocess, 697.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 759ms/step\n",
      "[[ 3.9384e-11  1.1175e-09  8.8894e-10  8.1535e-16     0.99997  1.1185e-05  1.8743e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 3.9384e-11  1.1175e-09  8.8894e-10  8.1535e-16     0.99997  1.1185e-05  1.8743e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[ 3.9384e-11  1.1175e-09  8.8894e-10  8.1535e-16     0.99997  1.1185e-05  1.8743e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.9384e-11  1.1175e-09  8.8894e-10  8.1535e-16     0.99997  1.1185e-05  1.8743e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 728.6ms\n",
      "Speed: 2.0ms preprocess, 728.6ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 1.5201e-11  5.4221e-10  1.8546e-09  4.6115e-16     0.99998  4.9146e-06  1.0759e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[ 1.5201e-11  5.4221e-10  1.8546e-09  4.6115e-16     0.99998  4.9146e-06  1.0759e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[ 1.5201e-11  5.4221e-10  1.8546e-09  4.6115e-16     0.99998  4.9146e-06  1.0759e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5201e-11  5.4221e-10  1.8546e-09  4.6115e-16     0.99998  4.9146e-06  1.0759e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 737.5ms\n",
      "Speed: 1.0ms preprocess, 737.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 1.0169e-11  5.6804e-10  2.4725e-09  2.4252e-16     0.99997  6.2717e-06  2.0201e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 1.0169e-11  5.6804e-10  2.4725e-09  2.4252e-16     0.99997  6.2717e-06  2.0201e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 1.0169e-11  5.6804e-10  2.4725e-09  2.4252e-16     0.99997  6.2717e-06  2.0201e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0169e-11  5.6804e-10  2.4725e-09  2.4252e-16     0.99997  6.2717e-06  2.0201e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 734.4ms\n",
      "Speed: 1.0ms preprocess, 734.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 8.6015e-12  4.2649e-09  1.9725e-09  2.9933e-16     0.99995  4.3277e-06  4.8409e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 8.6015e-12  4.2649e-09  1.9725e-09  2.9933e-16     0.99995  4.3277e-06  4.8409e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[ 8.6015e-12  4.2649e-09  1.9725e-09  2.9933e-16     0.99995  4.3277e-06  4.8409e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.6015e-12  4.2649e-09  1.9725e-09  2.9933e-16     0.99995  4.3277e-06  4.8409e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 708.1ms\n",
      "Speed: 1.0ms preprocess, 708.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 6.0871e-12  6.9213e-09  2.2185e-09  1.2918e-16     0.99992  6.7385e-06   7.522e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 6.0871e-12  6.9213e-09  2.2185e-09  1.2918e-16     0.99992  6.7385e-06   7.522e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 6.0871e-12  6.9213e-09  2.2185e-09  1.2918e-16     0.99992  6.7385e-06   7.522e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.0871e-12  6.9213e-09  2.2185e-09  1.2918e-16     0.99992  6.7385e-06   7.522e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 722.2ms\n",
      "Speed: 1.0ms preprocess, 722.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 4.9502e-12  5.3456e-09  3.4796e-09  1.1684e-16      0.9998  1.7645e-05  0.00017972]]\n",
      "4\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 4.9502e-12  5.3456e-09  3.4796e-09  1.1684e-16      0.9998  1.7645e-05  0.00017972]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 4.9502e-12  5.3456e-09  3.4796e-09  1.1684e-16      0.9998  1.7645e-05  0.00017972]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.9502e-12  5.3456e-09  3.4796e-09  1.1684e-16      0.9998  1.7645e-05  0.00017972]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 774.8ms\n",
      "Speed: 1.6ms preprocess, 774.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[  7.361e-12  5.9997e-09  2.6927e-09  1.5957e-16     0.99911  5.2779e-05  0.00083379]]\n",
      "4\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[  7.361e-12  5.9997e-09  2.6927e-09  1.5957e-16     0.99911  5.2779e-05  0.00083379]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[  7.361e-12  5.9997e-09  2.6927e-09  1.5957e-16     0.99911  5.2779e-05  0.00083379]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.361e-12  5.9997e-09  2.6927e-09  1.5957e-16     0.99911  5.2779e-05  0.00083379]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 689.6ms\n",
      "Speed: 1.0ms preprocess, 689.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 6.4055e-12   5.105e-09   3.872e-09  2.1078e-16     0.99744  0.00018684   0.0023695]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 6.4055e-12   5.105e-09   3.872e-09  2.1078e-16     0.99744  0.00018684   0.0023695]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 6.4055e-12   5.105e-09   3.872e-09  2.1078e-16     0.99744  0.00018684   0.0023695]]\n",
      "4\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.4055e-12   5.105e-09   3.872e-09  2.1078e-16     0.99744  0.00018684   0.0023695]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 693.5ms\n",
      "Speed: 0.0ms preprocess, 693.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[ 1.3066e-11  9.0049e-09  7.1285e-09  3.4941e-16     0.99379  0.00047051   0.0057361]]\n",
      "4\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[ 1.3066e-11  9.0049e-09  7.1285e-09  3.4941e-16     0.99379  0.00047051   0.0057361]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 1.3066e-11  9.0049e-09  7.1285e-09  3.4941e-16     0.99379  0.00047051   0.0057361]]\n",
      "4\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3066e-11  9.0049e-09  7.1285e-09  3.4941e-16     0.99379  0.00047051   0.0057361]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 704.5ms\n",
      "Speed: 1.0ms preprocess, 704.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 1.1318e-11  7.7958e-09  7.9882e-09  2.8553e-16     0.98977  0.00087977   0.0093453]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 1.1318e-11  7.7958e-09  7.9882e-09  2.8553e-16     0.98977  0.00087977   0.0093453]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 1.1318e-11  7.7958e-09  7.9882e-09  2.8553e-16     0.98977  0.00087977   0.0093453]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1318e-11  7.7958e-09  7.9882e-09  2.8553e-16     0.98977  0.00087977   0.0093453]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 694.7ms\n",
      "Speed: 1.0ms preprocess, 694.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 9.2741e-12  4.9062e-09  6.6568e-09  2.1922e-16     0.98937   0.0010592   0.0095727]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 9.2741e-12  4.9062e-09  6.6568e-09  2.1922e-16     0.98937   0.0010592   0.0095727]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 9.2741e-12  4.9062e-09  6.6568e-09  2.1922e-16     0.98937   0.0010592   0.0095727]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.2741e-12  4.9062e-09  6.6568e-09  2.1922e-16     0.98937   0.0010592   0.0095727]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 687.3ms\n",
      "Speed: 0.0ms preprocess, 687.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 1.1455e-11  3.1898e-09  6.3185e-09  2.9485e-16      0.9907   0.0013129    0.007992]]\n",
      "4\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 1.1455e-11  3.1898e-09  6.3185e-09  2.9485e-16      0.9907   0.0013129    0.007992]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 1.1455e-11  3.1898e-09  6.3185e-09  2.9485e-16      0.9907   0.0013129    0.007992]]\n",
      "4\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1455e-11  3.1898e-09  6.3185e-09  2.9485e-16      0.9907   0.0013129    0.007992]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 697.0ms\n",
      "Speed: 1.0ms preprocess, 697.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 6.4519e-12  8.8323e-09  1.2422e-08  2.2807e-16     0.99072   0.0027544    0.006521]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 6.4519e-12  8.8323e-09  1.2422e-08  2.2807e-16     0.99072   0.0027544    0.006521]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 6.4519e-12  8.8323e-09  1.2422e-08  2.2807e-16     0.99072   0.0027544    0.006521]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 6.4519e-12  8.8323e-09  1.2422e-08  2.2807e-16     0.99072   0.0027544    0.006521]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 697.2ms\n",
      "Speed: 1.0ms preprocess, 697.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 3.3988e-14  5.5535e-11  2.2098e-09  9.4914e-19     0.99993  4.3611e-05  2.6685e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 3.3988e-14  5.5535e-11  2.2098e-09  9.4914e-19     0.99993  4.3611e-05  2.6685e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 3.3988e-14  5.5535e-11  2.2098e-09  9.4914e-19     0.99993  4.3611e-05  2.6685e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.3988e-14  5.5535e-11  2.2098e-09  9.4914e-19     0.99993  4.3611e-05  2.6685e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 728.8ms\n",
      "Speed: 1.0ms preprocess, 728.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 6.2787e-14  4.1949e-11  3.0026e-09  2.6422e-18     0.99997  1.4947e-05  1.9425e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 6.2787e-14  4.1949e-11  3.0026e-09  2.6422e-18     0.99997  1.4947e-05  1.9425e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 6.2787e-14  4.1949e-11  3.0026e-09  2.6422e-18     0.99997  1.4947e-05  1.9425e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.2787e-14  4.1949e-11  3.0026e-09  2.6422e-18     0.99997  1.4947e-05  1.9425e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 701.2ms\n",
      "Speed: 1.2ms preprocess, 701.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[  8.253e-14  3.9385e-10  3.2139e-09  2.8663e-17     0.99982  2.6613e-05  0.00015663]]\n",
      "4\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[  8.253e-14  3.9385e-10  3.2139e-09  2.8663e-17     0.99982  2.6613e-05  0.00015663]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[  8.253e-14  3.9385e-10  3.2139e-09  2.8663e-17     0.99982  2.6613e-05  0.00015663]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.253e-14  3.9385e-10  3.2139e-09  2.8663e-17     0.99982  2.6613e-05  0.00015663]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 691.2ms\n",
      "Speed: 1.0ms preprocess, 691.2ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[  9.083e-14  1.7032e-10  1.4668e-09  2.9797e-17     0.99991   2.916e-05  5.7708e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[  9.083e-14  1.7032e-10  1.4668e-09  2.9797e-17     0.99991   2.916e-05  5.7708e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[  9.083e-14  1.7032e-10  1.4668e-09  2.9797e-17     0.99991   2.916e-05  5.7708e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.083e-14  1.7032e-10  1.4668e-09  2.9797e-17     0.99991   2.916e-05  5.7708e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 716.5ms\n",
      "Speed: 0.0ms preprocess, 716.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[  7.856e-14  2.9916e-10  8.3728e-10  2.3248e-18     0.99836  0.00043744   0.0011982]]\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[  7.856e-14  2.9916e-10  8.3728e-10  2.3248e-18     0.99836  0.00043744   0.0011982]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[  7.856e-14  2.9916e-10  8.3728e-10  2.3248e-18     0.99836  0.00043744   0.0011982]]\n",
      "4\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[  7.856e-14  2.9916e-10  8.3728e-10  2.3248e-18     0.99836  0.00043744   0.0011982]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 726.9ms\n",
      "Speed: 2.0ms preprocess, 726.9ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 9.7903e-12  2.4141e-08  8.4312e-10  2.5323e-18     0.99474   0.0039551   0.0013066]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 9.7903e-12  2.4141e-08  8.4312e-10  2.5323e-18     0.99474   0.0039551   0.0013066]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 9.7903e-12  2.4141e-08  8.4312e-10  2.5323e-18     0.99474   0.0039551   0.0013066]]\n",
      "4\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 9.7903e-12  2.4141e-08  8.4312e-10  2.5323e-18     0.99474   0.0039551   0.0013066]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 726.6ms\n",
      "Speed: 1.0ms preprocess, 726.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 8.4313e-11  3.3842e-08  7.5345e-09  2.1825e-17     0.73611     0.23752    0.026364]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 8.4313e-11  3.3842e-08  7.5345e-09  2.1825e-17     0.73611     0.23752    0.026364]]\n",
      "4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 8.4313e-11  3.3842e-08  7.5345e-09  2.1825e-17     0.73611     0.23752    0.026364]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 8.4313e-11  3.3842e-08  7.5345e-09  2.1825e-17     0.73611     0.23752    0.026364]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 750.6ms\n",
      "Speed: 1.0ms preprocess, 750.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 8.6177e-11  1.3285e-08  2.2127e-09  8.0305e-18     0.63649     0.35662   0.0068969]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 8.6177e-11  1.3285e-08  2.2127e-09  8.0305e-18     0.63649     0.35662   0.0068969]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 8.6177e-11  1.3285e-08  2.2127e-09  8.0305e-18     0.63649     0.35662   0.0068969]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.6177e-11  1.3285e-08  2.2127e-09  8.0305e-18     0.63649     0.35662   0.0068969]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 712.3ms\n",
      "Speed: 0.9ms preprocess, 712.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 8.7821e-11   4.494e-09  2.8185e-10   4.255e-18     0.15806     0.83568   0.0062594]]\n",
      "5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 8.7821e-11   4.494e-09  2.8185e-10   4.255e-18     0.15806     0.83568   0.0062594]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 8.7821e-11   4.494e-09  2.8185e-10   4.255e-18     0.15806     0.83568   0.0062594]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 8.7821e-11   4.494e-09  2.8185e-10   4.255e-18     0.15806     0.83568   0.0062594]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 709.9ms\n",
      "Speed: 2.0ms preprocess, 709.9ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[  2.346e-11  8.4642e-09  2.8898e-11  1.0704e-18    0.061955     0.91381     0.02423]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[  2.346e-11  8.4642e-09  2.8898e-11  1.0704e-18    0.061955     0.91381     0.02423]]\n",
      "5\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "[[  2.346e-11  8.4642e-09  2.8898e-11  1.0704e-18    0.061955     0.91381     0.02423]]\n",
      "5\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.346e-11  8.4642e-09  2.8898e-11  1.0704e-18    0.061955     0.91381     0.02423]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 715.1ms\n",
      "Speed: 2.0ms preprocess, 715.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 3.4358e-11  8.2843e-09  1.0466e-10  2.6137e-18     0.08104     0.88441    0.034546]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 3.4358e-11  8.2843e-09  1.0466e-10  2.6137e-18     0.08104     0.88441    0.034546]]\n",
      "5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 3.4358e-11  8.2843e-09  1.0466e-10  2.6137e-18     0.08104     0.88441    0.034546]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 3.4358e-11  8.2843e-09  1.0466e-10  2.6137e-18     0.08104     0.88441    0.034546]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 743.3ms\n",
      "Speed: 0.0ms preprocess, 743.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 9.0615e-11  5.5554e-09  2.6897e-10  6.3819e-18     0.31731     0.63716    0.045532]]\n",
      "5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 9.0615e-11  5.5554e-09  2.6897e-10  6.3819e-18     0.31731     0.63716    0.045532]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 9.0615e-11  5.5554e-09  2.6897e-10  6.3819e-18     0.31731     0.63716    0.045532]]\n",
      "5\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.0615e-11  5.5554e-09  2.6897e-10  6.3819e-18     0.31731     0.63716    0.045532]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 709.7ms\n",
      "Speed: 1.0ms preprocess, 709.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 1.1057e-10  2.1941e-09   1.389e-10  8.6892e-18     0.17309     0.72151      0.1054]]\n",
      "5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 1.1057e-10  2.1941e-09   1.389e-10  8.6892e-18     0.17309     0.72151      0.1054]]\n",
      "5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 1.1057e-10  2.1941e-09   1.389e-10  8.6892e-18     0.17309     0.72151      0.1054]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1057e-10  2.1941e-09   1.389e-10  8.6892e-18     0.17309     0.72151      0.1054]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 759.7ms\n",
      "Speed: 1.0ms preprocess, 759.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 5.1877e-11  9.2598e-10  8.0133e-11  4.4109e-18     0.14794      0.7767    0.075359]]\n",
      "5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 5.1877e-11  9.2598e-10  8.0133e-11  4.4109e-18     0.14794      0.7767    0.075359]]\n",
      "5\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[ 5.1877e-11  9.2598e-10  8.0133e-11  4.4109e-18     0.14794      0.7767    0.075359]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 5.1877e-11  9.2598e-10  8.0133e-11  4.4109e-18     0.14794      0.7767    0.075359]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 698.8ms\n",
      "Speed: 1.0ms preprocess, 698.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[ 3.4785e-11  5.0391e-10  1.0174e-10  3.0098e-18     0.13941     0.79865    0.061934]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 3.4785e-11  5.0391e-10  1.0174e-10  3.0098e-18     0.13941     0.79865    0.061934]]\n",
      "5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[ 3.4785e-11  5.0391e-10  1.0174e-10  3.0098e-18     0.13941     0.79865    0.061934]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 3.4785e-11  5.0391e-10  1.0174e-10  3.0098e-18     0.13941     0.79865    0.061934]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 712.4ms\n",
      "Speed: 1.0ms preprocess, 712.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 5.7724e-11  2.2079e-10   7.328e-11  6.4988e-19    0.019575     0.95491    0.025519]]\n",
      "5\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 5.7724e-11  2.2079e-10   7.328e-11  6.4988e-19    0.019575     0.95491    0.025519]]\n",
      "5\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[ 5.7724e-11  2.2079e-10   7.328e-11  6.4988e-19    0.019575     0.95491    0.025519]]\n",
      "5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 5.7724e-11  2.2079e-10   7.328e-11  6.4988e-19    0.019575     0.95491    0.025519]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 refrigerator, 693.3ms\n",
      "Speed: 0.9ms preprocess, 693.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[ 1.2857e-11  2.0861e-10  2.7345e-11  1.6185e-19   0.0045674     0.95228    0.043151]]\n",
      "5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 1.2857e-11  2.0861e-10  2.7345e-11  1.6185e-19   0.0045674     0.95228    0.043151]]\n",
      "5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 1.2857e-11  2.0861e-10  2.7345e-11  1.6185e-19   0.0045674     0.95228    0.043151]]\n",
      "5\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2857e-11  2.0861e-10  2.7345e-11  1.6185e-19   0.0045674     0.95228    0.043151]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 698.0ms\n",
      "Speed: 0.9ms preprocess, 698.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 2.3006e-12  1.2845e-11  2.7819e-11  3.4609e-20    0.001702     0.96309    0.035211]]\n",
      "5\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[ 2.3006e-12  1.2845e-11  2.7819e-11  3.4609e-20    0.001702     0.96309    0.035211]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 2.3006e-12  1.2845e-11  2.7819e-11  3.4609e-20    0.001702     0.96309    0.035211]]\n",
      "5\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.3006e-12  1.2845e-11  2.7819e-11  3.4609e-20    0.001702     0.96309    0.035211]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 672.2ms\n",
      "Speed: 1.0ms preprocess, 672.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[ 3.7616e-12  3.8545e-11  2.4263e-11  4.8803e-20   0.0014139     0.97773    0.020857]]\n",
      "5\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[ 3.7616e-12  3.8545e-11  2.4263e-11  4.8803e-20   0.0014139     0.97773    0.020857]]\n",
      "5\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[ 3.7616e-12  3.8545e-11  2.4263e-11  4.8803e-20   0.0014139     0.97773    0.020857]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 3.7616e-12  3.8545e-11  2.4263e-11  4.8803e-20   0.0014139     0.97773    0.020857]]\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 702.2ms\n",
      "Speed: 1.0ms preprocess, 702.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 7.4387e-12  3.3969e-11  2.2001e-11  2.6358e-20  0.00076095     0.97979    0.019452]]\n",
      "5\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[ 7.4387e-12  3.3969e-11  2.2001e-11  2.6358e-20  0.00076095     0.97979    0.019452]]\n",
      "5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[ 7.4387e-12  3.3969e-11  2.2001e-11  2.6358e-20  0.00076095     0.97979    0.019452]]\n",
      "5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[ 7.4387e-12  3.3969e-11  2.2001e-11  2.6358e-20  0.00076095     0.97979    0.019452]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "vid_file = './dataset/parthiv/15.mp4'\n",
    "\n",
    "vidcap = cv2.VideoCapture(vid_file)\n",
    "length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "mask_count = 0\n",
    "thresh = 127\n",
    "message = 'Analyzing...'\n",
    "m2 = ' '\n",
    "fps = 0\n",
    "\n",
    "pretrained_weight = './yolov8x-seg.pt'\n",
    "model = YOLO(pretrained_weight)\n",
    "new_model = load_model('./fine_tuned.h5')\n",
    "\n",
    "mask_dir = './output/masks/'\n",
    "mask_files = glob.glob(mask_dir+ '/*')\n",
    "for f in mask_files:\n",
    "    os.remove(f)\n",
    "\n",
    "while success:\n",
    "    start = time.time()\n",
    "    if(count%4 == 0):\n",
    "        results = model(image)\n",
    "        masks = results[0].masks\n",
    "        if masks:\n",
    "            m2 = 'YOLO v8 = Inference: {0} ms | Preprocess: {1} ms | Postprocess: {2} ms' .format(round(results[0].speed['inference'], 2), round(results[0].speed['preprocess'], 2), round(results[0].speed['postprocess'], 2))\n",
    "            mask_count = mask_count+1\n",
    "            ms = masks.data.numpy()\n",
    "            cv2.imwrite(mask_dir + str(count) + '.png', ms[0,:,:]*255)\n",
    "        \n",
    "    if(mask_count >= 10):\n",
    "        image_data = []\n",
    "        files = os.listdir('./output/masks/')\n",
    "        for f in files:\n",
    "            im = cv2.imread('./output/masks/'+'/'+f, 0)\n",
    "            im_bw = cv2.threshold(im, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "            item = image_extract(im_bw, (64, 128))\n",
    "            if(np.max(item) != 0):\n",
    "                image_data.append(item)\n",
    "        gei = np.mean(image_data,axis=0)\n",
    "\n",
    "        res_img = cv2.resize(gei, (224,224))\n",
    "        test_img = cv2.merge([res_img, res_img, res_img])\n",
    "        test_img = test_img/255\n",
    "        test_img = np.reshape(test_img, (1, 224, 224, 3))\n",
    "        \n",
    "        preds = new_model.predict(test_img)\n",
    "        print(preds)\n",
    "        prediction = np.argmax(preds)\n",
    "        print(prediction)\n",
    "        for name, label in lables.items():\n",
    "            if label == prediction:\n",
    "                message = 'Detected : ' + name + ' (' + str(round(preds[0][prediction]*100, 2)) + '% Accuracy)'\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "    mask_out = cv2.merge([ms[0,:,:]*255, ms[0,:,:]*255, ms[0,:,:]*255])\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (25, 35)\n",
    "    org1 = (25, 60)\n",
    "    org2 = (25, 330)\n",
    "    org3 = (495, 330)\n",
    "    fontScale = 0.8\n",
    "    fontScale2 = 0.45\n",
    "    fontScale3 = 0.65\n",
    "    color = (0, 0, 0)\n",
    "    color2 = (0, 0, 255)\n",
    "    color3 = (255, 255, 255)\n",
    "    color4 = (255, 0, 255)\n",
    "    color5 = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    thickness2 = 1\n",
    "\n",
    "    title1 = 'Live'\n",
    "    org4 = (25, 30)\n",
    "    title2 = 'YOLO v8 generated mask'\n",
    "\n",
    "    fps_msg = 'FPS: ' + str(round(fps/1000, 2))\n",
    "    image = cv2.putText(image, fps_msg, org3, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "    image = cv2.putText(image, title1, org4, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "        \n",
    "    mask_out = cv2.putText(mask_out, title2, org4, font, \n",
    "                   fontScale3, color4, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # mask_out = cv2.putText(mask_out, m2, org2, font, \n",
    "    #                 fontScale2, color5, thickness2, cv2.LINE_AA)\n",
    "    \n",
    "    prompt = np.zeros((95, 640, 3))*255\n",
    "    prompt = cv2.putText(prompt, message, org, font, \n",
    "                    fontScale, color5, thickness, cv2.LINE_AA)\n",
    "    prompt = cv2.putText(prompt, m2, org1, font, \n",
    "                    fontScale2, color3, thickness2, cv2.LINE_AA)\n",
    "    if(image is None):\n",
    "        cv2.destroyAllWindows()\n",
    "    if(image is not None):\n",
    "        # cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)/255\n",
    "        disp = np.concatenate((cv2.resize(image/255, (640, 280)), cv2.resize(mask_out, (640, 280))), axis=0)\n",
    "        info = np.concatenate((disp, prompt), axis=0)\n",
    "        cv2.imshow('Live', info)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    end = time.time()\n",
    "    seconds = end - start \n",
    "    fps  = length / seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
