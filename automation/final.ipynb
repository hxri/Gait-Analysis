{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_center(img,is_round=True):\n",
    "    Y = img.mean(axis=1)\n",
    "    X = img.mean(axis=0)\n",
    "    Y_ = np.sum(np.arange(Y.shape[0]) * Y)/np.sum(Y)\n",
    "    X_ = np.sum(np.arange(X.shape[0]) * X)/np.sum(X)\n",
    "    if is_round:\n",
    "        return int(round(X_)),int(round(Y_))\n",
    "    return X_,Y_\n",
    "\n",
    "def image_extract(img,newsize):\n",
    "    if (len(np.where(img.mean(axis=0)!=0)[0]) != 0):\n",
    "        x_s = np.where(img.mean(axis=0)!=0)[0].min()\n",
    "        x_e = np.where(img.mean(axis=0)!=0)[0].max()\n",
    "        \n",
    "        y_s = np.where(img.mean(axis=1)!=0)[0].min()\n",
    "        y_e = np.where(img.mean(axis=1)!=0)[0].max()\n",
    "        \n",
    "        x_c,_ = mass_center(img)\n",
    "        x_s = x_c-newsize[1]//2\n",
    "        x_e = x_c+newsize[1]//2\n",
    "        img = img[y_s:y_e,x_s if x_s>0 else 0:x_e if x_e<img.shape[1] else img.shape[1]]\n",
    "        return cv2.resize(img,newsize)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = {'Abhirami': 0,\n",
    "            'Aswathy': 1,\n",
    "            'Ayana': 2,\n",
    "            'Lekshmi': 3,\n",
    "            'Nandana': 4,\n",
    "            'Shilpa': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 936.1ms\n",
      "Speed: 4.0ms preprocess, 936.1ms inference, 25.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 805.4ms\n",
      "Speed: 1.0ms preprocess, 805.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 799.4ms\n",
      "Speed: 1.0ms preprocess, 799.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 763.3ms\n",
      "Speed: 1.5ms preprocess, 763.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 757.3ms\n",
      "Speed: 0.9ms preprocess, 757.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 773.5ms\n",
      "Speed: 2.0ms preprocess, 773.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 791.4ms\n",
      "Speed: 1.0ms preprocess, 791.4ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 838.5ms\n",
      "Speed: 0.9ms preprocess, 838.5ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 toilet, 809.0ms\n",
      "Speed: 0.9ms preprocess, 809.0ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 toilet, 781.6ms\n",
      "Speed: 1.0ms preprocess, 781.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[     0.1063  1.8704e-12  1.0976e-07     0.18573     0.70795  1.1917e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[     0.1063  1.8704e-12  1.0976e-07     0.18573     0.70795  1.1917e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[[     0.1063  1.8704e-12  1.0976e-07     0.18573     0.70795  1.1917e-05]]\n",
      "4\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.1063  1.8704e-12  1.0976e-07     0.18573     0.70795  1.1917e-05]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 toilet, 804.8ms\n",
      "Speed: 1.9ms preprocess, 804.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[   0.030424  2.0513e-13  4.9595e-07    0.081139     0.88844  5.2758e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[   0.030424  2.0513e-13  4.9595e-07    0.081139     0.88844  5.2758e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[   0.030424  2.0513e-13  4.9595e-07    0.081139     0.88844  5.2758e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.030424  2.0513e-13  4.9595e-07    0.081139     0.88844  5.2758e-07]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 820.6ms\n",
      "Speed: 1.0ms preprocess, 820.6ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[    0.46996   1.359e-13  1.0271e-06     0.38654      0.1435  9.4892e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[    0.46996   1.359e-13  1.0271e-06     0.38654      0.1435  9.4892e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[    0.46996   1.359e-13  1.0271e-06     0.38654      0.1435  9.4892e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.46996   1.359e-13  1.0271e-06     0.38654      0.1435  9.4892e-07]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 840.4ms\n",
      "Speed: 1.0ms preprocess, 840.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[    0.76241  9.1643e-14  2.2197e-07     0.18232    0.055268  3.8528e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[    0.76241  9.1643e-14  2.2197e-07     0.18232    0.055268  3.8528e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[    0.76241  9.1643e-14  2.2197e-07     0.18232    0.055268  3.8528e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.76241  9.1643e-14  2.2197e-07     0.18232    0.055268  3.8528e-07]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 toilet, 786.7ms\n",
      "Speed: 1.0ms preprocess, 786.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "[[    0.91145  1.1973e-13  1.6256e-07    0.087342    0.001208  1.3158e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[    0.91145  1.1973e-13  1.6256e-07    0.087342    0.001208  1.3158e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[    0.91145  1.1973e-13  1.6256e-07    0.087342    0.001208  1.3158e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.91145  1.1973e-13  1.6256e-07    0.087342    0.001208  1.3158e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 767.3ms\n",
      "Speed: 1.0ms preprocess, 767.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[    0.78453  9.1697e-14  4.3079e-07     0.21397   0.0014967  6.2597e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.78453  9.1697e-14  4.3079e-07     0.21397   0.0014967  6.2597e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.78453  9.1697e-14  4.3079e-07     0.21397   0.0014967  6.2597e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.78453  9.1697e-14  4.3079e-07     0.21397   0.0014967  6.2597e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 851.8ms\n",
      "Speed: 1.0ms preprocess, 851.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[    0.68582  3.2348e-13  6.9431e-07     0.31281   0.0013553  1.1864e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.68582  3.2348e-13  6.9431e-07     0.31281   0.0013553  1.1864e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.68582  3.2348e-13  6.9431e-07     0.31281   0.0013553  1.1864e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.68582  3.2348e-13  6.9431e-07     0.31281   0.0013553  1.1864e-05]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 822.1ms\n",
      "Speed: 2.0ms preprocess, 822.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[    0.88948  1.0668e-12  1.3243e-07     0.10767   0.0028491  4.5915e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.88948  1.0668e-12  1.3243e-07     0.10767   0.0028491  4.5915e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[    0.88948  1.0668e-12  1.3243e-07     0.10767   0.0028491  4.5915e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.88948  1.0668e-12  1.3243e-07     0.10767   0.0028491  4.5915e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 720.6ms\n",
      "Speed: 1.0ms preprocess, 720.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[    0.94486  5.9661e-13  2.8035e-08    0.054316  0.00081673  4.6528e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[    0.94486  5.9661e-13  2.8035e-08    0.054316  0.00081673  4.6528e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[    0.94486  5.9661e-13  2.8035e-08    0.054316  0.00081673  4.6528e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.94486  5.9661e-13  2.8035e-08    0.054316  0.00081673  4.6528e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 toilet, 752.6ms\n",
      "Speed: 1.0ms preprocess, 752.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.92092  5.1717e-13  1.8239e-07    0.076437   0.0026134  2.7625e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[    0.92092  5.1717e-13  1.8239e-07    0.076437   0.0026134  2.7625e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[    0.92092  5.1717e-13  1.8239e-07    0.076437   0.0026134  2.7625e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.92092  5.1717e-13  1.8239e-07    0.076437   0.0026134  2.7625e-05]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 toilet, 808.4ms\n",
      "Speed: 1.0ms preprocess, 808.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.93326  7.9525e-13  1.0069e-07    0.065926  0.00079135  1.9198e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[    0.93326  7.9525e-13  1.0069e-07    0.065926  0.00079135  1.9198e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.93326  7.9525e-13  1.0069e-07    0.065926  0.00079135  1.9198e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.93326  7.9525e-13  1.0069e-07    0.065926  0.00079135  1.9198e-05]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 toilet, 790.8ms\n",
      "Speed: 1.5ms preprocess, 790.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[    0.95674  5.4993e-13  1.1077e-07    0.042468  0.00078369  1.0959e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[    0.95674  5.4993e-13  1.1077e-07    0.042468  0.00078369  1.0959e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[    0.95674  5.4993e-13  1.1077e-07    0.042468  0.00078369  1.0959e-05]]\n",
      "0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.95674  5.4993e-13  1.1077e-07    0.042468  0.00078369  1.0959e-05]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 784.4ms\n",
      "Speed: 1.0ms preprocess, 784.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[    0.89454  1.0255e-12  3.7735e-07     0.10419   0.0012664  3.4893e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[    0.89454  1.0255e-12  3.7735e-07     0.10419   0.0012664  3.4893e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[    0.89454  1.0255e-12  3.7735e-07     0.10419   0.0012664  3.4893e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.89454  1.0255e-12  3.7735e-07     0.10419   0.0012664  3.4893e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 768.3ms\n",
      "Speed: 1.0ms preprocess, 768.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[    0.91972  1.2265e-12  1.0586e-06    0.078483   0.0017994  1.8638e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[    0.91972  1.2265e-12  1.0586e-06    0.078483   0.0017994  1.8638e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[    0.91972  1.2265e-12  1.0586e-06    0.078483   0.0017994  1.8638e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[    0.91972  1.2265e-12  1.0586e-06    0.078483   0.0017994  1.8638e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 751.7ms\n",
      "Speed: 0.0ms preprocess, 751.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.93022  1.0738e-11  2.3277e-06     0.04965    0.020124  1.8448e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[    0.93022  1.0738e-11  2.3277e-06     0.04965    0.020124  1.8448e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[    0.93022  1.0738e-11  2.3277e-06     0.04965    0.020124  1.8448e-06]]\n",
      "0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[    0.93022  1.0738e-11  2.3277e-06     0.04965    0.020124  1.8448e-06]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 746.4ms\n",
      "Speed: 1.0ms preprocess, 746.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[    0.90628  5.8597e-12  5.3913e-07    0.081508    0.012214  4.4261e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[    0.90628  5.8597e-12  5.3913e-07    0.081508    0.012214  4.4261e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[    0.90628  5.8597e-12  5.3913e-07    0.081508    0.012214  4.4261e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[    0.90628  5.8597e-12  5.3913e-07    0.081508    0.012214  4.4261e-07]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 787.4ms\n",
      "Speed: 2.0ms preprocess, 787.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[    0.87683  1.1762e-11  4.8893e-07    0.081945    0.041225  2.8625e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[[    0.87683  1.1762e-11  4.8893e-07    0.081945    0.041225  2.8625e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[    0.87683  1.1762e-11  4.8893e-07    0.081945    0.041225  2.8625e-07]]\n",
      "0\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[    0.87683  1.1762e-11  4.8893e-07    0.081945    0.041225  2.8625e-07]]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 748.5ms\n",
      "Speed: 1.0ms preprocess, 748.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[    0.86127   1.582e-11  5.1615e-07    0.066912    0.071822  2.1253e-07]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "vid_file = './dataset/abhirami/6.mp4'\n",
    "\n",
    "vidcap = cv2.VideoCapture(vid_file)\n",
    "length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "mask_count = 0\n",
    "thresh = 127\n",
    "message = 'Analyzing...'\n",
    "m2 = ' '\n",
    "fps = 0\n",
    "\n",
    "pretrained_weight = './yolov8x-seg.pt'\n",
    "model = YOLO(pretrained_weight)\n",
    "new_model = load_model('./fine_tuned.h5')\n",
    "\n",
    "mask_dir = './output/masks/'\n",
    "mask_files = glob.glob(mask_dir+ '/*')\n",
    "for f in mask_files:\n",
    "    os.remove(f)\n",
    "\n",
    "while success:\n",
    "    start = time.time()\n",
    "    if(count%4 == 0):\n",
    "        results = model(image)\n",
    "        masks = results[0].masks\n",
    "        if masks:\n",
    "            m2 = 'YOLO v8 = Inference: {0} ms | Preprocess: {1} ms | Postprocess: {2} ms' .format(round(results[0].speed['inference'], 2), round(results[0].speed['preprocess'], 2), round(results[0].speed['postprocess'], 2))\n",
    "            mask_count = mask_count+1\n",
    "            ms = masks.data.numpy()\n",
    "            cv2.imwrite(mask_dir + str(count) + '.png', ms[0,:,:]*255)\n",
    "        \n",
    "    if(mask_count >= 10):\n",
    "        image_data = []\n",
    "        files = os.listdir('./output/masks/')\n",
    "        for f in files:\n",
    "            im = cv2.imread('./output/masks/'+'/'+f, 0)\n",
    "            im_bw = cv2.threshold(im, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "            item = image_extract(im_bw, (64, 128))\n",
    "            if(np.max(item) != 0):\n",
    "                image_data.append(item)\n",
    "        gei = np.mean(image_data,axis=0)\n",
    "\n",
    "        res_img = cv2.resize(gei, (224,224))\n",
    "        test_img = cv2.merge([res_img, res_img, res_img])\n",
    "        test_img = test_img/255\n",
    "        test_img = np.reshape(test_img, (1, 224, 224, 3))\n",
    "        \n",
    "        preds = new_model.predict(test_img)\n",
    "        print(preds)\n",
    "        prediction = np.argmax(preds)\n",
    "        print(prediction)\n",
    "        for name, label in lables.items():\n",
    "            if label == prediction:\n",
    "                message = 'Detected : ' + name + ' (' + str(round(preds[0][prediction]*100, 2)) + '% Accuracy)'\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "    mask_out = cv2.merge([ms[0,:,:]*255, ms[0,:,:]*255, ms[0,:,:]*255])\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (25, 35)\n",
    "    org1 = (25, 60)\n",
    "    org2 = (25, 330)\n",
    "    org3 = (495, 320)\n",
    "    fontScale = 0.8\n",
    "    fontScale2 = 0.45\n",
    "    fontScale3 = 0.65\n",
    "    color = (0, 0, 0)\n",
    "    color2 = (0, 0, 255)\n",
    "    color3 = (255, 255, 255)\n",
    "    color4 = (255, 0, 255)\n",
    "    color5 = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    thickness2 = 1\n",
    "\n",
    "    title1 = 'Live'\n",
    "    org4 = (25, 30)\n",
    "    title2 = 'YOLO v8 generated mask'\n",
    "\n",
    "    fps_msg = 'FPS: ' + str(round(fps/1000, 2))\n",
    "    image = cv2.putText(image, fps_msg, org3, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "    image = cv2.putText(image, title1, org4, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    mask_out = cv2.putText(mask_out, title2, org4, font, \n",
    "                   fontScale3, color4, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # mask_out = cv2.putText(mask_out, m2, org2, font, \n",
    "    #                 fontScale2, color5, thickness2, cv2.LINE_AA)\n",
    "    \n",
    "    prompt = np.zeros((95, 640, 3))*255\n",
    "    prompt = cv2.putText(prompt, message, org, font, \n",
    "                    fontScale, color5, thickness, cv2.LINE_AA)\n",
    "    prompt = cv2.putText(prompt, m2, org1, font, \n",
    "                    fontScale2, color3, thickness2, cv2.LINE_AA)\n",
    "    if(image is None):\n",
    "        cv2.destroyAllWindows()\n",
    "    if(image is not None):\n",
    "        # cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)/255\n",
    "        disp = np.concatenate((image/255, mask_out), axis=0)\n",
    "        info = np.concatenate((disp, prompt), axis=0)\n",
    "        cv2.imshow('Live', info)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    end = time.time()\n",
    "    seconds = end - start \n",
    "    fps  = length / seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
