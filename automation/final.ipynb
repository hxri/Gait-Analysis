{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_center(img,is_round=True):\n",
    "    Y = img.mean(axis=1)\n",
    "    X = img.mean(axis=0)\n",
    "    Y_ = np.sum(np.arange(Y.shape[0]) * Y)/np.sum(Y)\n",
    "    X_ = np.sum(np.arange(X.shape[0]) * X)/np.sum(X)\n",
    "    if is_round:\n",
    "        return int(round(X_)),int(round(Y_))\n",
    "    return X_,Y_\n",
    "\n",
    "def image_extract(img,newsize):\n",
    "    if (len(np.where(img.mean(axis=0)!=0)[0]) != 0):\n",
    "        x_s = np.where(img.mean(axis=0)!=0)[0].min()\n",
    "        x_e = np.where(img.mean(axis=0)!=0)[0].max()\n",
    "        \n",
    "        y_s = np.where(img.mean(axis=1)!=0)[0].min()\n",
    "        y_e = np.where(img.mean(axis=1)!=0)[0].max()\n",
    "        \n",
    "        x_c,_ = mass_center(img)\n",
    "        x_s = x_c-newsize[1]//2\n",
    "        x_e = x_c+newsize[1]//2\n",
    "        img = img[y_s:y_e,x_s if x_s>0 else 0:x_e if x_e<img.shape[1] else img.shape[1]]\n",
    "        return cv2.resize(img,newsize)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = {'Abhirami': 0,\n",
    "            'Aswathy': 1,\n",
    "            'Ayana': 2,\n",
    "            'Lekshmi': 3,\n",
    "            'Nandana': 4,\n",
    "            'Parthiv': 5,\n",
    "            'Shilpa': 6,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 971.9ms\n",
      "Speed: 6.5ms preprocess, 971.9ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 2 handbags, 962.3ms\n",
      "Speed: 0.0ms preprocess, 962.3ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 handbag, 908.3ms\n",
      "Speed: 0.0ms preprocess, 908.3ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 handbag, 901.8ms\n",
      "Speed: 0.0ms preprocess, 901.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 handbag, 931.1ms\n",
      "Speed: 0.0ms preprocess, 931.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 handbag, 888.4ms\n",
      "Speed: 0.0ms preprocess, 888.4ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 3 handbags, 928.4ms\n",
      "Speed: 4.5ms preprocess, 928.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 backpack, 1 handbag, 895.4ms\n",
      "Speed: 0.0ms preprocess, 895.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 backpack, 897.3ms\n",
      "Speed: 0.0ms preprocess, 897.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 352x640 1 person, 1 backpack, 908.0ms\n",
      "Speed: 0.0ms preprocess, 908.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "[[ 7.7394e-06   1.519e-07    0.050421  1.5999e-07     0.94957  1.6467e-06  3.4169e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 7.7394e-06   1.519e-07    0.050421  1.5999e-07     0.94957  1.6467e-06  3.4169e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 7.7394e-06   1.519e-07    0.050421  1.5999e-07     0.94957  1.6467e-06  3.4169e-07]]\n",
      "4\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.7394e-06   1.519e-07    0.050421  1.5999e-07     0.94957  1.6467e-06  3.4169e-07]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 handbag, 999.2ms\n",
      "Speed: 0.0ms preprocess, 999.2ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 7.9268e-05  0.00057685      0.1002  2.2322e-07     0.89914  5.7563e-07  3.7755e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 7.9268e-05  0.00057685      0.1002  2.2322e-07     0.89914  5.7563e-07  3.7755e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 7.9268e-05  0.00057685      0.1002  2.2322e-07     0.89914  5.7563e-07  3.7755e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[ 7.9268e-05  0.00057685      0.1002  2.2322e-07     0.89914  5.7563e-07  3.7755e-06]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 handbag, 895.8ms\n",
      "Speed: 0.0ms preprocess, 895.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 7.6345e-05  0.00014525    0.071681  1.8485e-07     0.92809  2.4738e-07  4.6869e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 7.6345e-05  0.00014525    0.071681  1.8485e-07     0.92809  2.4738e-07  4.6869e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 7.6345e-05  0.00014525    0.071681  1.8485e-07     0.92809  2.4738e-07  4.6869e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 7.6345e-05  0.00014525    0.071681  1.8485e-07     0.92809  2.4738e-07  4.6869e-06]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 886.9ms\n",
      "Speed: 0.0ms preprocess, 886.9ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 3.9352e-05  2.4174e-05     0.12066  1.1169e-07     0.87927  4.1283e-07  6.0163e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 3.9352e-05  2.4174e-05     0.12066  1.1169e-07     0.87927  4.1283e-07  6.0163e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 3.9352e-05  2.4174e-05     0.12066  1.1169e-07     0.87927  4.1283e-07  6.0163e-06]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.9352e-05  2.4174e-05     0.12066  1.1169e-07     0.87927  4.1283e-07  6.0163e-06]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 840.5ms\n",
      "Speed: 2.6ms preprocess, 840.5ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[ 0.00012901  7.4681e-05     0.60797   7.676e-06     0.39144  0.00013249  0.00024995]]\n",
      "2\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[ 0.00012901  7.4681e-05     0.60797   7.676e-06     0.39144  0.00013249  0.00024995]]\n",
      "2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[ 0.00012901  7.4681e-05     0.60797   7.676e-06     0.39144  0.00013249  0.00024995]]\n",
      "2\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00012901  7.4681e-05     0.60797   7.676e-06     0.39144  0.00013249  0.00024995]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 872.5ms\n",
      "Speed: 0.0ms preprocess, 872.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[ 0.00019385   3.558e-05     0.52138  1.6943e-05     0.47798  0.00021222  0.00018894]]\n",
      "2\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 0.00019385   3.558e-05     0.52138  1.6943e-05     0.47798  0.00021222  0.00018894]]\n",
      "2\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 0.00019385   3.558e-05     0.52138  1.6943e-05     0.47798  0.00021222  0.00018894]]\n",
      "2\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00019385   3.558e-05     0.52138  1.6943e-05     0.47798  0.00021222  0.00018894]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 910.7ms\n",
      "Speed: 4.7ms preprocess, 910.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[ 0.00012256  0.00053768     0.14848  3.8563e-06     0.84985   8.441e-05   0.0009203]]\n",
      "4\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 0.00012256  0.00053768     0.14848  3.8563e-06     0.84985   8.441e-05   0.0009203]]\n",
      "4\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 0.00012256  0.00053768     0.14848  3.8563e-06     0.84985   8.441e-05   0.0009203]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00012256  0.00053768     0.14848  3.8563e-06     0.84985   8.441e-05   0.0009203]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 898.1ms\n",
      "Speed: 0.0ms preprocess, 898.1ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 0.00010548  0.00071749     0.24661  5.2604e-06     0.75056  0.00019912   0.0017962]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 0.00010548  0.00071749     0.24661  5.2604e-06     0.75056  0.00019912   0.0017962]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 0.00010548  0.00071749     0.24661  5.2604e-06     0.75056  0.00019912   0.0017962]]\n",
      "4\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00010548  0.00071749     0.24661  5.2604e-06     0.75056  0.00019912   0.0017962]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 backpack, 927.2ms\n",
      "Speed: 0.0ms preprocess, 927.2ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[ 0.00065457    0.091962     0.13053  1.4634e-05     0.69694    0.052771    0.027126]]\n",
      "4\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[ 0.00065457    0.091962     0.13053  1.4634e-05     0.69694    0.052771    0.027126]]\n",
      "4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 0.00065457    0.091962     0.13053  1.4634e-05     0.69694    0.052771    0.027126]]\n",
      "4\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[ 0.00065457    0.091962     0.13053  1.4634e-05     0.69694    0.052771    0.027126]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 backpack, 986.2ms\n",
      "Speed: 0.0ms preprocess, 986.2ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 9.7986e-05     0.14005    0.064582  3.0734e-06     0.65028    0.040938     0.10405]]\n",
      "4\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[ 9.7986e-05     0.14005    0.064582  3.0734e-06     0.65028    0.040938     0.10405]]\n",
      "4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 9.7986e-05     0.14005    0.064582  3.0734e-06     0.65028    0.040938     0.10405]]\n",
      "4\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 9.7986e-05     0.14005    0.064582  3.0734e-06     0.65028    0.040938     0.10405]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 backpack, 883.0ms\n",
      "Speed: 0.0ms preprocess, 883.0ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 2.4086e-05     0.33518    0.020065  1.8473e-06     0.28411    0.079359     0.28126]]\n",
      "1\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 2.4086e-05     0.33518    0.020065  1.8473e-06     0.28411    0.079359     0.28126]]\n",
      "1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 2.4086e-05     0.33518    0.020065  1.8473e-06     0.28411    0.079359     0.28126]]\n",
      "1\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.4086e-05     0.33518    0.020065  1.8473e-06     0.28411    0.079359     0.28126]]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 backpack, 941.9ms\n",
      "Speed: 0.0ms preprocess, 941.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 6.7868e-06     0.30476   0.0087531  7.9897e-08     0.46447    0.056194     0.16582]]\n",
      "4\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[ 6.7868e-06     0.30476   0.0087531  7.9897e-08     0.46447    0.056194     0.16582]]\n",
      "4\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 6.7868e-06     0.30476   0.0087531  7.9897e-08     0.46447    0.056194     0.16582]]\n",
      "4\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[ 6.7868e-06     0.30476   0.0087531  7.9897e-08     0.46447    0.056194     0.16582]]\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 backpack, 899.2ms\n",
      "Speed: 4.7ms preprocess, 899.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 4.1707e-06      0.3558   0.0095978  1.3413e-07     0.13922     0.21498     0.28039]]\n",
      "1\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 4.1707e-06      0.3558   0.0095978  1.3413e-07     0.13922     0.21498     0.28039]]\n",
      "1\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[ 4.1707e-06      0.3558   0.0095978  1.3413e-07     0.13922     0.21498     0.28039]]\n",
      "1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 4.1707e-06      0.3558   0.0095978  1.3413e-07     0.13922     0.21498     0.28039]]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 352x640 1 person, 1 handbag, 860.6ms\n",
      "Speed: 0.0ms preprocess, 860.6ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 1.5336e-06    0.040051  0.00022927  1.1685e-07   0.0030678     0.91534    0.041311]]\n",
      "5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[ 1.5336e-06    0.040051  0.00022927  1.1685e-07   0.0030678     0.91534    0.041311]]\n",
      "5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 1.5336e-06    0.040051  0.00022927  1.1685e-07   0.0030678     0.91534    0.041311]]\n",
      "5\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 1.5336e-06    0.040051  0.00022927  1.1685e-07   0.0030678     0.91534    0.041311]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 1 backpack, 906.1ms\n",
      "Speed: 0.0ms preprocess, 906.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 5.2808e-05     0.24006   0.0096156  5.7298e-06    0.029353      0.6625    0.058413]]\n",
      "5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[ 5.2808e-05     0.24006   0.0096156  5.7298e-06    0.029353      0.6625    0.058413]]\n",
      "5\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 5.2808e-05     0.24006   0.0096156  5.7298e-06    0.029353      0.6625    0.058413]]\n",
      "5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 5.2808e-05     0.24006   0.0096156  5.7298e-06    0.029353      0.6625    0.058413]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 352x640 1 person, 847.1ms\n",
      "Speed: 0.0ms preprocess, 847.1ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[ 2.9867e-06   0.0033415    0.010116  2.3021e-06    0.014209     0.67784     0.29449]]\n",
      "5\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[ 2.9867e-06   0.0033415    0.010116  2.3021e-06    0.014209     0.67784     0.29449]]\n",
      "5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[ 2.9867e-06   0.0033415    0.010116  2.3021e-06    0.014209     0.67784     0.29449]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "vid_file = '../../dataset/aswathy/7.mp4'\n",
    "\n",
    "vidcap = cv2.VideoCapture(vid_file)\n",
    "length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "mask_count = 0\n",
    "thresh = 127\n",
    "message = 'Analyzing...'\n",
    "m2 = ' '\n",
    "fps = 0\n",
    "\n",
    "pretrained_weight = './yolov8x-seg.pt'\n",
    "model = YOLO(pretrained_weight)\n",
    "new_model = load_model('./fine_tuned.h5')\n",
    "\n",
    "mask_dir = './output/masks/'\n",
    "mask_files = glob.glob(mask_dir+ '/*')\n",
    "for f in mask_files:\n",
    "    os.remove(f)\n",
    "\n",
    "while success:\n",
    "    start = time.time()\n",
    "    if(count%4 == 0):\n",
    "        results = model(image)\n",
    "        masks = results[0].masks\n",
    "        if masks:\n",
    "            m2 = 'YOLO v8 = Inference: {0} ms | Preprocess: {1} ms | Postprocess: {2} ms' .format(round(results[0].speed['inference'], 2), round(results[0].speed['preprocess'], 2), round(results[0].speed['postprocess'], 2))\n",
    "            mask_count = mask_count+1\n",
    "            ms = masks.data.numpy()\n",
    "            cv2.imwrite(mask_dir + str(count) + '.png', ms[0,:,:]*255)\n",
    "        \n",
    "    if(mask_count >= 10):\n",
    "        image_data = []\n",
    "        files = os.listdir('./output/masks/')\n",
    "        for f in files:\n",
    "            im = cv2.imread('./output/masks/'+'/'+f, 0)\n",
    "            im_bw = cv2.threshold(im, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "            item = image_extract(im_bw, (64, 128))\n",
    "            if(np.max(item) != 0):\n",
    "                image_data.append(item)\n",
    "        gei = np.mean(image_data,axis=0)\n",
    "\n",
    "        res_img = cv2.resize(gei, (224,224))\n",
    "        test_img = cv2.merge([res_img, res_img, res_img])\n",
    "        test_img = test_img/255\n",
    "        test_img = np.reshape(test_img, (1, 224, 224, 3))\n",
    "        \n",
    "        preds = new_model.predict(test_img)\n",
    "        print(preds)\n",
    "        prediction = np.argmax(preds)\n",
    "        print(prediction)\n",
    "        for name, label in lables.items():\n",
    "            if label == prediction:\n",
    "                message = 'Detected : ' + name + ' (' + str(round(preds[0][prediction]*100, 2)) + '% Accuracy)'\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "    mask_out = cv2.merge([ms[0,:,:]*255, ms[0,:,:]*255, ms[0,:,:]*255])\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (25, 35)\n",
    "    org1 = (25, 60)\n",
    "    org2 = (25, 330)\n",
    "    org3 = (495, 330)\n",
    "    fontScale = 0.8\n",
    "    fontScale2 = 0.45\n",
    "    fontScale3 = 0.65\n",
    "    color = (0, 0, 0)\n",
    "    color2 = (0, 0, 255)\n",
    "    color3 = (255, 255, 255)\n",
    "    color4 = (255, 0, 255)\n",
    "    color5 = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    thickness2 = 1\n",
    "\n",
    "    title1 = 'Live'\n",
    "    org4 = (25, 30)\n",
    "    title2 = 'YOLO v8 generated mask'\n",
    "\n",
    "    fps_msg = 'FPS: ' + str(round(fps/1000, 2))\n",
    "    image = cv2.putText(image, fps_msg, org3, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "    image = cv2.putText(image, title1, org4, font, \n",
    "                   fontScale3, color2, thickness, cv2.LINE_AA)\n",
    "        \n",
    "    mask_out = cv2.putText(mask_out, title2, org4, font, \n",
    "                   fontScale3, color4, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    # mask_out = cv2.putText(mask_out, m2, org2, font, \n",
    "    #                 fontScale2, color5, thickness2, cv2.LINE_AA)\n",
    "    \n",
    "    prompt = np.zeros((95, 640, 3))*255\n",
    "    prompt = cv2.putText(prompt, message, org, font, \n",
    "                    fontScale, color5, thickness, cv2.LINE_AA)\n",
    "    prompt = cv2.putText(prompt, m2, org1, font, \n",
    "                    fontScale2, color3, thickness2, cv2.LINE_AA)\n",
    "    if(image is None):\n",
    "        cv2.destroyAllWindows()\n",
    "    if(image is not None):\n",
    "        # cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)/255\n",
    "        disp = np.concatenate((cv2.resize(image/255, (640, 280)), cv2.resize(mask_out, (640, 280))), axis=0)\n",
    "        info = np.concatenate((disp, prompt), axis=0)\n",
    "        cv2.imshow('Live', info)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    end = time.time()\n",
    "    seconds = end - start \n",
    "    fps  = length / seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
