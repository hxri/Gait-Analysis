{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Attention, GlobalAveragePooling2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./trained_model.h5', compile=False)\n",
    "# model.layers.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1311744   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 124)               127100    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,696,828\n",
      "Trainable params: 3,662,716\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.Sequential(model.layers[:-1])\n",
    "\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(Dense(6, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1311744   \n",
      "                                                                 \n",
      " output (Dense)              (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,575,878\n",
      "Trainable params: 6,150\n",
      "Non-trainable params: 3,569,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = './fine_tune_dataset/train/'\n",
    "test_data_dir = './fine_tune_dataset/test/'\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1320 images belonging to 6 classes.\n",
      "Found 6 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical') # set as training data\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    test_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "330/330 [==============================] - 5s 8ms/step - loss: 3.7163 - accuracy: 0.4424\n",
      "Epoch 2/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.7497 - accuracy: 0.8076\n",
      "Epoch 3/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.4576 - accuracy: 0.8538\n",
      "Epoch 4/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.3102 - accuracy: 0.8932\n",
      "Epoch 5/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1948 - accuracy: 0.9273\n",
      "Epoch 6/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1778 - accuracy: 0.9333\n",
      "Epoch 7/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1935 - accuracy: 0.9280\n",
      "Epoch 8/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1415 - accuracy: 0.9576\n",
      "Epoch 9/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1202 - accuracy: 0.9583\n",
      "Epoch 10/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.1335 - accuracy: 0.9523\n",
      "Epoch 11/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0957 - accuracy: 0.9614\n",
      "Epoch 12/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0731 - accuracy: 0.9735\n",
      "Epoch 13/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0915 - accuracy: 0.9735\n",
      "Epoch 14/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0621 - accuracy: 0.9758\n",
      "Epoch 15/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0653 - accuracy: 0.9773\n",
      "Epoch 16/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0772 - accuracy: 0.9780\n",
      "Epoch 17/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0662 - accuracy: 0.9788\n",
      "Epoch 18/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0601 - accuracy: 0.9864\n",
      "Epoch 19/60\n",
      "330/330 [==============================] - 3s 9ms/step - loss: 0.0771 - accuracy: 0.9773\n",
      "Epoch 20/60\n",
      "330/330 [==============================] - 6s 19ms/step - loss: 0.0582 - accuracy: 0.9803\n",
      "Epoch 21/60\n",
      "330/330 [==============================] - 6s 18ms/step - loss: 0.0465 - accuracy: 0.9841\n",
      "Epoch 22/60\n",
      "330/330 [==============================] - 6s 19ms/step - loss: 0.0721 - accuracy: 0.9833\n",
      "Epoch 23/60\n",
      "330/330 [==============================] - 6s 18ms/step - loss: 0.0464 - accuracy: 0.9856\n",
      "Epoch 24/60\n",
      "330/330 [==============================] - 6s 18ms/step - loss: 0.0433 - accuracy: 0.9886\n",
      "Epoch 25/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0622 - accuracy: 0.9765\n",
      "Epoch 26/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0353 - accuracy: 0.9917\n",
      "Epoch 27/60\n",
      "330/330 [==============================] - 4s 13ms/step - loss: 0.0577 - accuracy: 0.9841\n",
      "Epoch 28/60\n",
      "330/330 [==============================] - 4s 13ms/step - loss: 0.0512 - accuracy: 0.9841\n",
      "Epoch 29/60\n",
      "330/330 [==============================] - 5s 14ms/step - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 30/60\n",
      "330/330 [==============================] - 5s 14ms/step - loss: 0.0358 - accuracy: 0.9886\n",
      "Epoch 31/60\n",
      "330/330 [==============================] - 5s 17ms/step - loss: 0.0416 - accuracy: 0.9894\n",
      "Epoch 32/60\n",
      "330/330 [==============================] - 5s 15ms/step - loss: 0.0408 - accuracy: 0.9856\n",
      "Epoch 33/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0353 - accuracy: 0.9902\n",
      "Epoch 34/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0374 - accuracy: 0.9886\n",
      "Epoch 35/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0234 - accuracy: 0.9962\n",
      "Epoch 36/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0276 - accuracy: 0.9955\n",
      "Epoch 37/60\n",
      "330/330 [==============================] - 5s 14ms/step - loss: 0.0268 - accuracy: 0.9932\n",
      "Epoch 38/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0273 - accuracy: 0.9947\n",
      "Epoch 39/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0219 - accuracy: 0.9962\n",
      "Epoch 40/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0229 - accuracy: 0.9962\n",
      "Epoch 41/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0242 - accuracy: 0.9955\n",
      "Epoch 42/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0236 - accuracy: 0.9947\n",
      "Epoch 43/60\n",
      "330/330 [==============================] - 5s 16ms/step - loss: 0.0182 - accuracy: 0.9992\n",
      "Epoch 44/60\n",
      "330/330 [==============================] - 6s 17ms/step - loss: 0.0228 - accuracy: 0.9962\n",
      "Epoch 45/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0163 - accuracy: 0.9992\n",
      "Epoch 46/60\n",
      "330/330 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9962\n",
      "Epoch 47/60\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.0187 - accuracy: 0.9977\n",
      "Epoch 48/60\n",
      "330/330 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9970\n",
      "Epoch 49/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0266 - accuracy: 0.9924\n",
      "Epoch 50/60\n",
      "330/330 [==============================] - 3s 10ms/step - loss: 0.0208 - accuracy: 0.9955\n",
      "Epoch 51/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0211 - accuracy: 0.9962\n",
      "Epoch 52/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0205 - accuracy: 0.9955\n",
      "Epoch 53/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0160 - accuracy: 0.9970\n",
      "Epoch 54/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0167 - accuracy: 0.9977\n",
      "Epoch 55/60\n",
      "330/330 [==============================] - 3s 9ms/step - loss: 0.0164 - accuracy: 0.9985\n",
      "Epoch 56/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9985\n",
      "Epoch 57/60\n",
      "330/330 [==============================] - 3s 8ms/step - loss: 0.0164 - accuracy: 0.9985\n",
      "Epoch 58/60\n",
      "330/330 [==============================] - 2s 6ms/step - loss: 0.0164 - accuracy: 0.9977\n",
      "Epoch 59/60\n",
      "330/330 [==============================] - 2s 6ms/step - loss: 0.0151 - accuracy: 0.9977\n",
      "Epoch 60/60\n",
      "330/330 [==============================] - 2s 6ms/step - loss: 0.0138 - accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    epochs = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 23ms/step - loss: 0.0012 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0012012965744361281, 1.0]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('./fine_tune_dataset/test/lekshmi/lekshmi_4.png')\n",
    "test_img = cv2.resize(test_img, (224,224))\n",
    "test_img = test_img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.reshape(test_img, (1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = new_model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abhirami\n"
     ]
    }
   ],
   "source": [
    "data = test_generator.class_indices\n",
    "\n",
    "search_label = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('fine_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
